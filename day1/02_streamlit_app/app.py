# app.py
import streamlit as st
import ui                   # UIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import llm                  # LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import database             # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import metrics              # è©•ä¾¡æŒ‡æ¨™ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import data                 # ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import torch
from transformers import pipeline
from config import MODEL_NAME
from huggingface_hub import HfFolder

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š ---
st.set_page_config(page_title="æ—¥æœ¬èªGPT-2ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")

# --- åˆæœŸåŒ–å‡¦ç† ---
metrics.initialize_nltk()
database.init_db()
data.ensure_initial_data()

# --- LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰ ---
@st.cache_resource
def load_model():
    """LLMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        st.info(f"Using device: {device}") # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
        pipe = pipeline(
            "text-generation",
            model=MODEL_NAME,
            device=device
        )
        st.success(f"ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return pipe
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

pipe = llm.load_model()

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---
st.title("ğŸ¤– Japanese GPT-2 Chatbot with Feedback")
st.write("æ—¥æœ¬èªGPT-2ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚è³ªå•ã‚’å…¥åŠ›ã—ã¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")
st.markdown("---")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
if 'page' not in st.session_state:
    st.session_state.page = "ãƒãƒ£ãƒƒãƒˆ"

page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    ["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†"],
    key="page_selector",
    index=["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†"].index(st.session_state.page),
    on_change=lambda: setattr(st.session_state, 'page', st.session_state.page_selector)
)

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
if st.session_state.page == "ãƒãƒ£ãƒƒãƒˆ":
    if pipe:
        st.subheader("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="input_text")
        if st.button("è³ªå•ã‚’é€ä¿¡"):
            with st.spinner("è€ƒãˆä¸­..."):
                try:
                    output = pipe(user_input, max_length=100, do_sample=True)[0]["generated_text"]
                    st.success(f"å›ç­”: {output}")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        st.error("ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
elif st.session_state.page == "å±¥æ­´é–²è¦§":
    ui.display_history_page()
elif st.session_state.page == "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
    ui.display_data_page()

# --- ãƒ•ãƒƒã‚¿ãƒ¼ ---
st.sidebar.markdown("---")
st.sidebar.info("é–‹ç™ºè€…: [Your Name]")
